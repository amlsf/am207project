\documentclass[11pt]{article}
\usepackage{common}
\usepackage[usenames, dvipsnames]{color}
\usepackage{setspace}
\usepackage{booktabs}
\usepackage{multirow}

\title{AM207 Final Project: \\ Exploring Optimization Strategies for \textit{Mastermind}}
\author{Gioia Domined\`o \and Amy Lee \and Kendrick Lo \and Reinier Maat}

\begin{document}
\maketitle{}

\begin{abstract}
\textcolor{red}{Insert abstract text.}
\end{abstract}

\pagestyle{plain}
\pagenumbering{arabic}

\section{Introduction}

The game Mastermind was invented in 1970 by Mordecai Meirowitz, and is similar to an earlier game called Bulls and Cows. There are many variations of the game\footnote{https://en.wikipedia.org/wiki/Mastermind\_(board\_game)\#Variations}, but they all follow a broadly consistent format. The game involves two players: a code-maker and a code-breaker. The code-maker selects a sequence of length L (usually 4), where each element in the sequence is chosen with replacement from one of C colors (usually 6). At each turn, the code-breaker guesses a sequence and receives feedback in the form of black pegs and white pegs, where the black pegs denote the number of correct guesses in the right position, and the white pegs denote the number of correct guesses in the wrong position. Based on this information, the code-breaker refines her guesses and attempts to crack the code within the maximum number of guesses (usually 10).

For our project, we set out to implement various strategies and algorithms for iteratively optimizing the code-breaker's guess at each turn. We compared the performance of these strategies based on the mean and standard deviation of the required number of guesses to win and the runtime across 20 random game initializations. In order to assess the extent to which the different solutions scale efficiently, we tested seven game setups of varying complexity.

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.7\textwidth]{img/game_setup}
\caption{Mastermind Framework}
\label{fig:game_setup}
\end{figure}

\newpage

\section{Optimization Methods}

It is helpful at this stage to introduce some mathematical notation to describe the game, which we will use consistently when describing the various methods that we tested. For simplicity, we use one-indexing in the formulas below; however, we note that the Python code for the game interface that we built is zero-indexed. \medskip

\noindent We define:
\begin{itemize}
\item set of possible colors: $C = \{1, ..., C\}$
\item set of positions in the code: $L = \{1, ..., L\}$
\item hidden code: $H_i \ \forall i \in L$
\item guess of the hidden code: $T_i \ \forall i \in L$
\item indicator function $\mathbb{1}_{A=B}$, which equals 1 if A=B and equals 0 otherwise
\end{itemize}

\noindent Using the above notation, we can denote the responses at each turn as follows:

\begin{itemize}
\item correct guesses in the right position: $B = \sum_{i=1}^L \mathbb{1}_{T_i=H_i} \ \forall i \in L$
\item correct guesses in the wrong position: $W = \sum_{i=1}^{C} \min(\sum_{j=1}^{L}\mathbb{1}_{H_j=i, G_i}, \sum_{j=1}^{L}\mathbb{1}_{T_j=i, G_i}) - B$
\end{itemize}

\subsection{Knuth's Five-Guess Algorithm}

The most commonly referenced optimization technique in the Mastermind literature is Knuth's five-guess algorithm \cite{knuth76} \textendash \ sometimes also referred to as the ``worst-case strategy" \textendash \ which can always solve the classic game configuration in five moves or less. This strategy always begins with the same initial guess of 1122 (or 0011, when zero-indexed); this choice is motivated by examples of other initial guesses that do not always lead to a solution in five moves. Our implementation uses this deterministic initial guess for the classic game configuration, but uses a random initial guess for all other configurations as analogous ``best" starting points are not defined in the literature.

After the initial guess, the algorithm determines the minimum number of codes that each guess would eliminate from the list of possibilities, and chooses one of the guesses that maximizes this number\footnote{Wikipedia refers to this as the minimax \textit{technique}. We note that this one-off maximization differs from the recursive minimax \textit{algorithm} that is also used in game theory.}. At each stage of the game, the set of possible codes is updated to only include codes that would have generated the same responses at each of the previous steps. This ensures that the state space shrinks with each subsequent guess.

\subsection{Random Search with Constraints / Random Sampling From Posterior}

This method is described in the Mastermind literature both as a constrained random search algorithm \cite{bernier1996solving} and in terms of posterior distribution updates \cite{vomlel2004bayesian}. We follow the latter approach below.

We start by defining the joint probability distribution over all possible code sequences as $P(H_1, ..., H_L)$. As we have no information, our prior is uniformly distributed.

\[
P(H_1=h_1, ..., H_L=h_l) = \frac{1}{C^L} ,\quad \text{for all combinations of }(h_1, ..., h_l)
\]

\noindent We can denote the evidence that obtain at each step as $e = (B, W)$, where B and W are defined as above, and use this to update the posterior joint distribution over code sequences as follows:

\[
    P(H_1=h_1, ..., H_L=h_l | e) = 
\begin{cases}
    \frac{1}{|s(e)|},& \text{if } (h_1, ..., h_l) \ \text{is a possible code}\\
    0,              & \text{otherwise}
\end{cases}
\]

\noindent where s(e) denotes the set of possible hidden codes, given the evidence, and $|s(e)|$ denotes the cardinality of this set. \medskip

\noindent We can define the posterior after multiple game steps analogously:

\[
    P(H_1=h_1, ..., H_L=h_l | e_1, ..., e_n) = 
\begin{cases}
    \frac{1}{| s(e_1) \ \cap \ ... \ \cap \ s(e_n) |},& \text{if } (h_1, ..., h_l) \ \text{is a possible code}\\
    0,              & \text{otherwise}
\end{cases}
\]

\noindent where $\ s(e_1) \ \cap \ ... \ \cap \ s(e_n)$ denotes the intersection of the sets of possible hidden codes, given the evidence at each step, and the entire denominator denotes the cardinality of this intersection.

We can use this framework to define the posterior updates at each round of the game, and then choose the next guess by sampling from the posterior distribution. Figure \ref{fig:num_guesses} shows how the number of possible guesses shrinks as the game progresses.

\subsection{Maximizing Shannon Entropy}

Entropy is a measure that is commonly used in information theory to quantify the average amount of information that is contained in a message. In the context of Mastermind, the ``message" is the response of black and white pins that is returned by the code-maker at each turn. The goal of the code-breaker is to choose guesses that create as even a distribution as possible between the various responses\footnote{http://www.geometer.org/mathcircles/mastermind.pdf}, as it will allow her to discard more possible codes at the next step.

Let us denote $r_i$ as the $i$th response category and R as the number of possible responses\footnote{For example, the classic version of the game with codes of length $4$ has 14 possible responses: $(4, 0), (3, 0), (2, 2), (2, 1), (2, 0), (1, 3), (1, 2), (1, 1), (1, 0), (0, 4), (0, 3), (0, 2), (0, 1), (0, 0)$.}. We can then define the entropy of the discrete response space $\{r_1, ... , r_R\}$ for a given guess as:

\[
H(\text{guess} | \text{possible codes}) = \sum_{i=1}^R P(r_i) I(r_i) = - \sum_{i=1}^R P(r_i) \log_bP(r_i)
\]

\noindent where $I(r_i)$ denotes the information content of the $i$th response category. We use $b=2$, meaning that we are measuring entropy in shannons, but note that any other value of $b$ would yield a consistent ranking between guesses.

Practically, we calculate the probability of each response category for a given guess by counting (and normalizing) the total number of possible responses in each category, given the hidden codes that are still possible at that particular stage in the game. The value will depend on the shape of the probability distribution across the response categories, with the minimum entropy of $0$ only achievable when there is certainty of a particular outcome (i.e. $log_2(1)=0$).

In order to improve her performance, the code-breaker will want to pick the guess that results in the highest entropy \textendash \ or, if there are ties, one of the best guesses \textendash \ in order to be able to discard more possible codes at the next step. This can be achieved through an exhaustive calculation of the entropy of all possible guesses at each stage or, for larger state spaces, through a local search technique such as simulated annealing or genetic algorithms.  Figure \ref{fig:entropy} illustrates how the distribution of entropy for the remaining possible guesses can change as the game progresses; this technique is particularly effective where there is a clear maximum value (e.g. at the third guess).

\subsection{Simulated Annealing}

Knuth's algorithm and maximizing shannon entropy are both examples of global optimization techniques. These approaches work well when optimizing across relatively small state spaces, but  are not guaranteed to scale well as the problem size increases. For example, maximizing shannon entropy has complexity $O(|s(e_i^2)|)$ at the $i$th round of the game, i.e. the runtime scales quadratically with the number of possible codes. More generally, we can use the starting number of possible codes ($C^L$) as an indicator of the complexity of the puzzle \textendash \ when this number becomes very large, approaches that allow us to approximate ``good" guesses without an exhaustive search through all possible codes become increasingly valuable.

Simulated annealing (SA) is one example of a local optimization method that can be effective in larger state spaces\footnote{The classical SA formulation involves the minimization of a cost function. Potential solutions are proposed iteratively, and their cost is compared to that of previously accepted solutions. Solutions with lower cost are automatically accepted, while solutions with greater cost are accepted with a certain probability. This probability decreases as the ``temperature" model parameter decreases, and varies inversely with the difference between the cost of the previously accepted solution and the cost of the newly proposed solution. In practice, SA can also be used to maximize objective functions, in addition to strictly minimizing cost functions.}. The effectiveness of this technique depends upon the objective function that is used to evaluate potential guesses, and the method that is used to propose potential new guesses. As mentioned above, one application of simulated annealing is as an alternative to the global maximization of entropy across all possible guesses. In this framework, new guesses are proposed by randomly picking from the set of remaining possible guesses, and are evaluated by calculating their entropy.

An alternative SA approach is described by Bernier et al. \cite{bernier1996solving}. Under this framework, new guesses are generated by introducing \textit{permutations} (swaps of code element pairs) and/or \textit{mutations} (changes to individual code elements) to the last code that was considered. The exact number of permutations and mutations is determined by the SA ``temperature'": the code can change significantly when the temperature is high, encouraging exploration of the state of potential next guesses, but will only change slightly when the temperature is lower (by which point we hope to be close to guessing the correct code), encouraging convergence to a ``good" solution.

In order to determine whether the proposed code is ``better" than the current code, Bernier et al. define an objective function based on the difference between the black and white pegs obtained from all previous guesses and the number of black and white pegs that would have been obtained if the newly proposed guess were the right code. The function is defined as

\[
\sum_{i=1}^n abs(\Delta n_w^i) + abs(\Delta n_w^i + \Delta n_b^i)
\]

\noindent where $n$ is the number of previous guesses made and $\Delta n_w^i $ and $\Delta n_b^i$ are the differences in white and black peg response when comparing the response that would be obtained if the proposed code were correct with the response it actually received when it had actually made the guess. 
%
%Intuitively, if ALL previous constraints (the black and white peg responses) are satisfied when our proposed guess is assumed to be the correct code, we will accept the proposal and formally enter the proposed guess since it may well be the correct answer. If most, but not all, of the previous constraints are satisfied, we know that we cannot possibly have a correct solution; nevertheless, we still accept the proposal with a certain probability and enter the proposed guess, with the hope of at least edging closer to an optimal solution. In this manner, we can usually approach a close-to-optimal solution relatively quickly, since the evaluation of each proposal requires considering only the previous guesses rather than the entire set of unguessed codes (the latter feature is common among all of the alternative methods discussed in this paper). 

\subsection{Genetic Algorithms}

\noindent \textcolor{red}{TODO}

%Both simulated annealing and genetic algorithms used the same cost function, where each combination is compared with all the previously played guesses. It is defined as:  
%$$C = \sum_{i=1}^n abs (\Delta n_W^i)  + abs(\Delta n_B^i + \Delta n_W^i )$$ 
%where $n$ is the number of guesses played and $\Delta n$ are the white and black peg differences between the target combination and the guess $i$. The number of different white and black pegs are computed and added to the cost such that the cost increases with the number of unsatisfied rules. In this manner, the constraints are added in a changing environment. 
%------------------------------------------------------------------------------------------------------
%Genetic algorithms are a type of evolutionary algorithm which generate solutions to optimization problems inspired by natural evolution. We create a population of 60 candidate solutions that we evolve towards better solutions in subsequent populations by selecting the most eligible combinations from previous generations, for a total 100 generations. In order to maintain diversity to efficiently explore the changing landscape, we apply four different types of alterations for each candidate solution: 
%
%1. Crossover: Given a two codes, each index in the first code has a 0.5 probability of being crossed with the corresponding index in the second code. 
%
%2. Mutation: With a 0.03 probability, crossover is followed by a mutation that replaces the color of one randomly chosen position by a random other color. 
%
%3. Permutation: With a 0.03 probability,  colors of two random positions are switched. 
%
%4. Inversion: With a 0.02 probability, two randomly chosen positions have their sequence of colors between these two positions are inverted. 
%------------------------------------------------------------------------------------------------------
%citation: Lotte Berghman, Efficient solutions for Mastermind using genetic algorithms. 
%------------------------------------------------------------------------------------------------------


\section{Experiments}

\noindent \textcolor{red}{TODO}

%variations on entropy - exclude first guess


%- note that especially as the state size gets large, we can still get decent results (although not necessarily the correct answer) with simulated annealing. The advantage of SA (using the Bernier objective method) was particularly noticeable when we fixed the number of colors and extended the code length: even at a small number of colors (e.g. 3), the time to evaluate algorithms other than this SA method grew exponentially, and evaluating guesses using these other algorithms quickly became impractical.

%Modifications to genetic algorithms for speed-up: 
%- The eligible codes are selected from a population based on the criteria that all the constraints are met which is when the function $C$ above is 0. From there, we need to decide which of the eligible codes will be the next guess. From experimenting, we did not see a major difference in just playing a randomly selected code from the set vs. other strategies such as playing a code that is more similar or different from the other previously played guesses. Therefore, in order to speed up the algorithm, we modified the genetic algorithm to play the first candidate that meets all the criteria rather than completing all 100 generations of populations. 

\section{Conclusion}

\noindent \textcolor{red}{TODO}

%
%We noted earlier that with simulated annealing using a simple objective function that only depended on previous guesses, a close-to-optimal solution can be attained relatively quickly, even as the set of unguessed codes became large.  Each proposal only requires a comparison with each of the previous guesses, which can be orders of magnitude smaller than that of the set of unguessed codes.  Although most of the other algorithms will outperform SA if the goal is to obtain the correct code and the game time is unrestricted (our analysis showed that SA will generally require more guesses to arrive at the correct code), when the state size is so large that a repeated search through all unguessed codes is not feasible, the SA model will, to its advantage, typically be able to arrive at an acceptable "close" solution within a short period of time.

%Gagneur & co - applications to selective phenotyping

\newpage
\appendix

\section{Figures}

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.6\textwidth]{img/num_guesses}
\caption{Evolution in number of possible guesses}
\label{fig:num_guesses}
\end{figure}

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.6\textwidth]{img/entropy}
\caption{Entropy distributions for classic game parameters}
\label{fig:entropy}
\end{figure}

\newpage
\section{Results by Optimization Method}

\subsection*{Game configuration: 4 positions, varying number of possible colors}

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/knuth_guesses}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/knuth_runtime}}
\caption{Knuth's algorithm}
\label{fig:knuth}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/randomsearch_guesses}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/randomsearch_runtime}}
\caption{Random search / Random sampling from posterior}
\label{fig:randomsearch}
\end{figure}

\newpage

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/entropyall_guesses}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/entropyall_runtime}}
\caption{Maximizing entropy (all steps)}
\label{fig:entropyall}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/entropyminusone_guesses}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/entropyminusone_runtime}}
\caption{Maximizing entropy (except first step)}
\label{fig:entropyminusone}
\end{figure}

\newpage

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/sabernier_guesses}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/sabernier_runtime}}
\caption{Simulated annealing (Bernier objective function)}
\label{fig:sabernier}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/saentropy_guesses}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/saentropy_runtime}}
\caption{Simulated annealing (entropy objective function)}
\label{fig:saentropy}
\end{figure}

\newpage

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/gabernier_guesses}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/gabernier_runtime}}
\caption{Genetic algorithms (Bernier objective function)}
\label{fig:gabernier}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/gaentropy_guesses}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/gaentropy_runtime}}
\caption{Genetic algorithms (entropy objective function)}
\label{fig:gaentropy}
\end{figure}

\newpage

\subsection*{Game configuration: 2 possible colors, varying number of positions}

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/knuth_guesses2}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/knuth_runtime2}}
\caption{Knuth's algorithm2}
\label{fig:knuth}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/randomsearch_guesses2}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/randomsearch_runtime2}}
\caption{Random search / Random sampling from posterior}
\label{fig:randomsearch2}
\end{figure}

\newpage

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/entropyall_guesses2}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/entropyall_runtime2}}
\caption{Maximizing entropy (all steps)}
\label{fig:entropyall2}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/entropyminusone_guesses2}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/entropyminusone_runtime2}}
\caption{Maximizing entropy (except first step)}
\label{fig:entropyminusone2}
\end{figure}

\newpage

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/sabernier_guesses2}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/sabernier_runtime2}}
\caption{Simulated annealing (Bernier objective function)}
\label{fig:sabernier2}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/saentropy_guesses2}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/saentropy_runtime2}}
\caption{Simulated annealing (entropy objective function)}
\label{fig:saentropy2}
\end{figure}

\newpage

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/gabernier_guesses2}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/gabernier_runtime2}}
\caption{Genetic algorithms (Bernier objective function)}
\label{fig:gabernier2}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[Number of guesses]{\includegraphics[width=3.4in]{img/gaentropy_guesses2}}
\subfloat[Runtime (seconds)]{\includegraphics[width=3.4in]{img/gaentropy_runtime2}}
\caption{Genetic algorithms (entropy objective function)}
\label{fig:gaentropy2}
\end{figure}

\newpage
\section{Results by Game Configuration}

\subsection*{Game configuration: 4 positions, varying number of possible colors}

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 4.0 & 0.000									& 0.021 & 0.002							\\
Random search / Random sampling				& 3.7 & 0.557									& 0.002 & 0.000							\\
Maximizing entropy (all steps)					& 3.8 & 0.510									& 0.193 & 0.010							\\
Maximizing entropy (except first step)			& 3.7 & 0.640									& 0.007 & 0.004							\\
Simulated annealing (Bernier objective function)	& 7.5 & 2.037									& 0.017 & 0.026							\\
Simulated annealing (entropy objective function)	& 3.5 & 0.805									& 0.003 & 0.001							\\
Genetic algorithms (Bernier objective function)		& 3.9 & 0.831									& 0.022 &	0.026							\\
Genetic algorithms (entropy objective function)		& 3.8 & 0.698									& 0.027 & 0.032							\\
\bottomrule
\end{tabular}
\end{center}
\caption{4 positions; 4 possible colors}
\label{fig:compare_4_4}
\end{table}

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 4.0 & 0.000									& 0.264 & 0.006							\\
Random search / Random sampling				& 4.5 & 0.742									& 0.006 & 0.001							\\
Maximizing entropy (all steps)					& 4.0 & 0.497									& 1.147 & 0.035							\\
Maximizing entropy (except first step)			& 4.0 & 0.894									& 0.042 &	0.017							\\
Simulated annealing (Bernier objective function)	& 8.0 & 1.359									& 0.042 & 0.129							\\
Simulated annealing (entropy objective function)	& 4.7 & 0.781									& 0.007 & 0.001							\\
Genetic algorithms (Bernier objective function)		& 4.0 & 0.837									& 0.160 & 0.289							\\
Genetic algorithms (entropy objective function)		& 4.5 & 0.740									& 0.273 & 0.442							\\
\bottomrule
\end{tabular}
\end{center}
\caption{4 positions; 5 possible colors}
\label{fig:compare_4_5}
\end{table}

\newpage

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 4.0 & 0.000									& 0.606 & 0.017							\\
Random search / Random sampling				& 4.8 & 0.994									& 0.013 & 0.003							\\
Maximizing entropy (all steps)					& 4.8 & 0.600									& 5.225 & 0.207							\\
Maximizing entropy (except first step)			& 4.4 & 0.663									& 0.145 & 0.099							\\
Simulated annealing (Bernier objective function)	& 8.0 & 1.844									& 0.268 & 0.421							\\
Simulated annealing (entropy objective function)	& 5.0 & 0.949									& 0.013 & 0.001							\\
Genetic algorithms (Bernier objective function)		& 4.8 & 0.622									& 0.230 & 0.472							\\
Genetic algorithms (entropy objective function)		& 5.0 & 1.000									& 0.376 & 0.660 							\\
\bottomrule
\end{tabular}
\end{center}
\caption{4 positions; 6 possible colors}
\label{fig:compare_4_6}
\end{table}

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 4.0 & 0.000									& 0.528 & 0.014							\\
Random search / Random sampling				& 5.0 & 1.023									& 0.023 & 0.002							\\
Maximizing entropy (all steps)					& 4.8 & 0.812									& 18.600 & 0.883							\\
Maximizing entropy (except first step)			& 4.8 & 0.766									& 0.669 & 0.407							\\
Simulated annealing (Bernier objective function)	& 9.2 & 1.077									& 0.069 & 0.224							\\
Simulated annealing (entropy objective function)	& 5.3 & 0.781									& 0.028 & 0.005							\\
Genetic algorithms (Bernier objective function)		& 5.0 & 0.707									& 2.432 & 3.576							\\
Genetic algorithms (entropy objective function)		& 5.5 & 0.742									& 1.384 & 2.043							\\
\bottomrule
\end{tabular}
\end{center}
\caption{4 positions; 7 possible colors}
\label{fig:compare_4_7}
\end{table}

\newpage

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 6.0 & 0.000									& 21.711 & 0.269							\\
Random search / Random sampling				& 5.4 & 1.114									& 0.044 & 0.005							\\
Maximizing entropy (all steps)					& 5.1 & 0.943									& 53.689 & 1.944							\\
Maximizing entropy (except first step)			& 5.4 & 0.735									& 1.464 & 1.162							\\
Simulated annealing (Bernier objective function)	& 9.1 & 1.578									& 0.290 & 0.478							\\
Simulated annealing (entropy objective function)	& 5.5 & 1.023									& 0.043 & 0.005							\\
Genetic algorithms (Bernier objective function)		& 5.3 & 0.954									& 25.809 & 65.751							\\
Genetic algorithms (entropy objective function)		& 5.5 & 0.973									& 7.866 & 22.396							\\
\bottomrule
\end{tabular}
\end{center}
\caption{4 positions; 8 possible colors}
\label{fig:compare_4_8}
\end{table}

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 6.0 & 0.000									& 67.299 & 1.928							\\
Random search / Random sampling				& 5.9 & 0.995									& 0.069 & 0.008							\\
Maximizing entropy (all steps)					& 5.8 & 1.043									& 149.057 & 11.014							\\
Maximizing entropy (except first step)			& 5.7 & 0.714									& 5.702 & 4.282							\\
Simulated annealing (Bernier objective function)	& 8.8 & 1.824									& 0.191 & 0.331							\\
Simulated annealing (entropy objective function)	& 6.2 & 1.288									& 0.091 & 0.021							\\
Genetic algorithms (Bernier objective function)		& 6.0 & 1.378									& 66.406 & 135.881							\\
Genetic algorithms (entropy objective function)		& 6.2 & 1.122									& 10.492 & 28.552							\\
\bottomrule
\end{tabular}
\end{center}
\caption{4 positions; 9 possible colors}
\label{fig:compare_4_9}
\end{table}

\newpage

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 6.0 & 0.000									& 84.160 & 9.606							\\
Random search / Random sampling				& 6.6 & 1.020									& 0.098 & 0.006							\\
Maximizing entropy (all steps)					& 5.8 & 1.062									& 344.603 & 21.921							\\
Maximizing entropy (except first step)			& 6.0 & 0.775									& 13.557 & 9.339							\\
Simulated annealing (Bernier objective function)	& 9.4 & 0.970									& 0.248 & 0.513							\\
Simulated annealing (entropy objective function)	& 6.0 & 1.304									& 0.127 & 0.009							\\
Genetic algorithms (Bernier objective function)		& 6.5 & 1.466									& 77.632 & 169.038							\\
Genetic algorithms (entropy objective function)		& 5.9 & 0.831									& 107.604 & 310.685						\\
\bottomrule
\end{tabular}
\end{center}
\caption{4 positions; 10 possible colors}
\label{fig:compare_4_10}
\end{table}

\newpage

\subsection*{Game configuration: 2 possible colors, varying number of positions}

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 3.0 & 0.000									& 0.001 & 	0.000							\\
Random search / Random sampling				& 2.9 & 0.624									& 0.000 & 0.000 							\\
Maximizing entropy (all steps)					& 2.4 & 0.800									& 0.001 & 0.000 							\\
Maximizing entropy (except first step)			& 3.0 & 0.921									& 0.001 & 0.000 							\\
Simulated annealing (Bernier objective function)	& 2.9 & 1.091									& 0.001 & 0.001 							\\
Simulated annealing (entropy objective function)	& 2.5 & 0.865									& 0.000 & 0.000 							\\
Genetic algorithms (Bernier objective function)		& 2.8 & 0.812									& 0.004 & 0.002 							\\
Genetic algorithms (entropy objective function)		& 3.1 & 0.943									& 0.006 & 0.003							\\
\bottomrule
\end{tabular}
\end{center}
\caption{2 possible colors; 4 positions}
\label{fig:compare_2_4}
\end{table}

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 3.8 & 0.766									& 0.002 & 0.000							\\
Random search / Random sampling				& 3.5 & 0.805									& 0.001 & 0.000							\\
Maximizing entropy (all steps)					& 3.6 & 1.068									& 0.005 & 0.001							\\
Maximizing entropy (except first step)			& 3.5 & 1.072									& 0.001 & 0.000							\\
Simulated annealing (Bernier objective function)	& 4.8 & 2.112									& 0.002 & 0.002							\\
Simulated annealing (entropy objective function)	& 3.2 & 1.220									& 0.001 & 0.000							\\
Genetic algorithms (Bernier objective function)		& 3.1 & 0.963									& 0.006 & 0.003							\\
Genetic algorithms (entropy objective function)		& 3.0 & 1.140									& 0.006 & 0.004							\\
\bottomrule
\end{tabular}
\end{center}
\caption{2 possible colors; 5 positions}
\label{fig:compare_2_5}
\end{table}

\newpage

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 3.8 & 0.748									& 0.004 & 0.002							\\
Random search / Random sampling				& 3.5 & 1.284									& 0.001 & 0.000							\\
Maximizing entropy (all steps)					& 3.4 & 0.917									& 0.016 & 0.001							\\
Maximizing entropy (except first step)			& 3.5 & 1.118									& 0.001 & 0.000							\\
Simulated annealing (Bernier objective function)	& 6.3 & 1.931									& 0.013 & 0.033							\\
Simulated annealing (entropy objective function)	& 3.2 & 1.327									& 0.001 & 0.000							\\
Genetic algorithms (Bernier objective function)		& 3.7 & 1.345									& 0.009 & 0.005							\\
Genetic algorithms (entropy objective function)		& 3.6 & 1.200									& 0.009 & 0.004							\\
\bottomrule
\end{tabular}
\end{center}
\caption{2 possible colors; 6 positions}
\label{fig:compare_2_6}
\end{table}

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 3.9 & 0.768									& 0.015 & 0.004							\\
Random search / Random sampling				& 3.9 & 1.261									& 0.002 & 0.000							\\
Maximizing entropy (all steps)					& 3.8 & 1.208									& 0.065 & 0.004							\\
Maximizing entropy (except first step)			& 4.1 & 1.136									& 0.003 & 0.001							\\
Simulated annealing (Bernier objective function)	& 5.3 & 1.590									& 0.008 & 0.012							\\
Simulated annealing (entropy objective function)	& 4.0 & 1.049									& 0.002 & 0.000							\\
Genetic algorithms (Bernier objective function)		& 3.7 & 1.054									& 0.012 & 0.013							\\
Genetic algorithms (entropy objective function)		& 4.0 & 1.342									& 0.015 & 0.009							\\
\bottomrule
\end{tabular}
\end{center}
\caption{2 possible colors; 7 positions}
\label{fig:compare_2_7}
\end{table}

\newpage

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 3.8 & 0.766									& 0.052 & 0.024							\\
Random search / Random sampling				& 4.3 & 1.236									& 0.004 & 0.001							\\
Maximizing entropy (all steps)					& 4.6 & 0.800									& 0.289 & 0.014							\\
Maximizing entropy (except first step)			& 4.6 & 1.241									& 0.009 & 0.004							\\
Simulated annealing (Bernier objective function)	& 6.1 & 2.142									& 0.010 & 0.015							\\
Simulated annealing (entropy objective function)	& 4.8 & 1.122									& 0.005 & 0.001							\\
Genetic algorithms (Bernier objective function)		& 4.8 & 0.994									& 0.035 & 0.041							\\
Genetic algorithms (entropy objective function)		& 4.2 & 1.568									& 0.034 & 0.025							\\
\bottomrule
\end{tabular}
\end{center}
\caption{2 possible colors; 8 positions}
\label{fig:compare_2_8}
\end{table}

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 4.8 & 0.766									& 0.221 & 0.074							\\
Random search / Random sampling				& 4.7 & 1.382									& 0.010 & 0.002							\\
Maximizing entropy (all steps)					& 4.8 & 1.410									& 1.323 & 0.075							\\
Maximizing entropy (except first step)			& 4.7 & 1.345									& 0.026 & 0.014							\\
Simulated annealing (Bernier objective function)	& 8.0 & 1.774									& 0.052 & 0.086							\\
Simulated annealing (entropy objective function)	& 4.7 & 1.345									& 0.011 & 0.002							\\
Genetic algorithms (Bernier objective function)		& 5.0 & 0.894									& 0.047 & 0.040							\\
Genetic algorithms (entropy objective function)		& 5.0 & 1.203									& 0.044 & 0.026							\\
\bottomrule
\end{tabular}
\end{center}
\caption{2 possible colors; 9 positions}
\label{fig:compare_2_9}
\end{table}

\newpage

\begin{table}[h!]
\begin{center}
\begin{tabular}{l c c c c}
\toprule
\multirow{2}{*}{\bfseries Optimization method} 		& \multicolumn{2}{c}{\bfseries Number of guesses} 		& \multicolumn{2}{c}{\bfseries Runtime (seconds)}	\\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}				& $\mu$ & $\sigma$								& $\mu$ & $\sigma$							\\
\cmidrule(lr){1-5}
Knuth's algorithm							& 5.4 & 0.583									& 0.803 & 0.367							\\
Random search / Random sampling				& 5.9 & 1.261									& 0.019 & 0.002							\\
Maximizing entropy (all steps)					& 5.7 & 0.792									& 5.654 & 0.339							\\
Maximizing entropy (except first step)			& 5.2 & 1.178									& 0.111 & 0.061							\\
Simulated annealing (Bernier objective function)	& 6.7 & 1.878									& 0.147 & 0.453							\\
Simulated annealing (entropy objective function)	& 5.5 & 1.203									& 0.021 & 0.001							\\
Genetic algorithms (Bernier objective function)		& 5.1 & 1.179									& 0.047 & 0.085							\\
Genetic algorithms (entropy objective function)		& 5.2 & 1.260									& 0.080 & 0.072							\\
\bottomrule
\end{tabular}
\end{center}
\caption{2 possible colors; 10 positions}
\label{fig:compare_2_10}
\end{table}

\newpage

\section{Additional Methods Tested}

\noindent \textcolor{red}{TODO}

\newpage



%For this project we also tried to deploy expectation maximization (EM) to solve for the hidden code. At first sight this may seem very intuitive, since the parameters of the problem?the colors, or numbers, in the hidden code?are unobserved. Treating this like a latent parameter, like on does in expectation-maximization may seem like a good approach to take.
%Trying to work out the mathematics of a Mastermind expectation maximization strategy yields the following. EM is typically used in problems where the likelihood is hard to evaluate directly. Therefore, we recursively maximize the expectation of the likelihood conditional on the data, until we converge to a set of parameters that is close to the maximum likelihood estimator. In Mastermind, however, the likelihood of the data given a set of parameters is not so hard to evaluate at all. Since the constraint on the problem is that the hidden code should logically allow for the number of black and white pegs appearing given a certain guess, there can be many hidden codes with a likelihood of 1, while the rest will have likelihood 0. For example, if my guess is 1234, and as a response I get back two black pegs, then I know two numbers are right. Any hidden code where two numbers are in the same position and the rest are not, could validly produce this outcome, e.g. the code 1255 or 1664, etcetera. Given that such a code is true, the likelihood that the response was two black pegs is 1, since this is deterministically produced by the rules of the game. Therefore, there will be a split in the solution space between codes that are possible given the responses (likelihood equals 1), and codes that are impossible (likelihood equals 0). EM, in this case, would then converge to some solution in the set of still allowable codes. Since the choice of a new code isn't directed by any possible information gains, this amounts to a random search across the space. If we make an informed decision here, the problem boils down to a strategy where one would maximize the information gain, for instance using entropy or some other metric.
%In conclusion, EM is probably not a good way to study the Mastermind problem, since the game is underconstrained and deterministic, leading to a space of many equally likely convergent solutions at any given round in the game. It may be more useful in estimating parameters of stochastic processes with a lot of data, rather than in making forward looking decisions where information gain plays a bigger role.

%necessary for non-cited references to show up
\nocite{runarsson2010adapting}
\nocite{merelo2010finding}
\nocite{doerr2013playing}
\nocite{merelo2013improving}
\nocite{neuwirth1982some}
\nocite{kooi2005yet}
\nocite{berghman2009efficient}

\bibliographystyle{plain} 
\bibliography{project}

\end{document}
